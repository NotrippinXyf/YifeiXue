{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80bd1d8",
   "metadata": {},
   "source": [
    "# Fake News Detection: Judging Tweet authenticity through comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a2ca72",
   "metadata": {},
   "source": [
    "Yifei Xue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a58d68",
   "metadata": {},
   "source": [
    "First step of experiment, import all packages and dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75beb158",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,plot_roc_curve,RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost \n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Bidirectional,Dropout,Embedding\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e24675",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasetforproject.xlsx'\n",
    "dataset = pd.read_excel(path)\n",
    "target = dataset['label']\n",
    "label = target.apply(lambda x:1 if x==True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42cc6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>Now 10 dead in a shooting there today RT \\\"@BB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>@BBCDanielS @BBCWorld I'm guessing this is bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>@BBCDanielS @BBCWorld why would you mention th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>@BBCDanielS @BBCWorld perps identified?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>Charlie Hebdo became well known for publishing...</td>\n",
       "      <td>@BBCDanielS @BBCWorld who is charlie hebdo?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             source  \\\n",
       "0  False  Charlie Hebdo became well known for publishing...   \n",
       "1  False  Charlie Hebdo became well known for publishing...   \n",
       "2  False  Charlie Hebdo became well known for publishing...   \n",
       "3  False  Charlie Hebdo became well known for publishing...   \n",
       "4  False  Charlie Hebdo became well known for publishing...   \n",
       "\n",
       "                                                text  \n",
       "0  Now 10 dead in a shooting there today RT \\\"@BB...  \n",
       "1  @BBCDanielS @BBCWorld I'm guessing this is bei...  \n",
       "2  @BBCDanielS @BBCWorld why would you mention th...  \n",
       "3            @BBCDanielS @BBCWorld perps identified?  \n",
       "4        @BBCDanielS @BBCWorld who is charlie hebdo?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6a88ca",
   "metadata": {},
   "source": [
    "data clean, remove all parts that i dont need in experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20aceff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordopt(text):\n",
    "    text = text.lower()\n",
    "    #\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4355d2",
   "metadata": {},
   "source": [
    "data split, we split the dataset to trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522b97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['text'].apply(wordopt)\n",
    "\n",
    "\n",
    "\n",
    "corpus = []\n",
    "dataset['text'].apply(lambda x: corpus.append(x))\n",
    "\n",
    "Tfidf = TfidfVectorizer()\n",
    "x_train,x_test,y_train,y_test = train_test_split(data,label,test_size=0.2,random_state=1)\n",
    "x_train = Tfidf.fit_transform((x_train))\n",
    "x_test = Tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49bfbfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    now  dead in a shooting there today rt    bbcd...\n",
       "1     bbcdaniels  bbcworld i m guessing this is bei...\n",
       "2     bbcdaniels  bbcworld why would you mention th...\n",
       "3               bbcdaniels  bbcworld perps identified \n",
       "4           bbcdaniels  bbcworld who is charlie hebdo \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600586b",
   "metadata": {},
   "source": [
    "LogicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b65f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr accuracy is 0.9191\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(x_train,y_train)\n",
    "y_pred_lr = LR.predict(x_test)\n",
    "acc_lr = accuracy_score(y_test,y_pred_lr)\n",
    "print(f'lr accuracy is {np.round(acc_lr,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c616dd7",
   "metadata": {},
   "source": [
    "Evalution of LogicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0cb6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[53 10]\n",
      " [ 1 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91        63\n",
      "           1       0.88      0.99      0.93        73\n",
      "\n",
      "    accuracy                           0.92       136\n",
      "   macro avg       0.93      0.91      0.92       136\n",
      "weighted avg       0.93      0.92      0.92       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "confusion_matrix(y_test,y_pred_lr)\n",
    "\n",
    "cfm = confusion_matrix(y_test,y_pred_lr)\n",
    "\n",
    "print(cfm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2688fd25",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ffef960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc accuracy is 0.9265\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "param = {'kernel':['linear','rbf'],'C':[0.001,0.01,0.1,1,10,100]}\n",
    "clf_svc = GridSearchCV(svc,param,cv=5,n_jobs=-1)\n",
    "clf_svc.fit(x_train,y_train)\n",
    "best_svc = clf_svc.best_estimator_\n",
    "best_svc.fit(x_train,y_train)\n",
    "y_pred_svc = best_svc.predict(x_test)\n",
    "acc_svc = accuracy_score(y_test,y_pred_svc)\n",
    "print(f'svc accuracy is {np.round(acc_svc,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8220e89",
   "metadata": {},
   "source": [
    "Evalution of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da7fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58  5]\n",
      " [ 5 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        63\n",
      "           1       0.93      0.93      0.93        73\n",
      "\n",
      "    accuracy                           0.93       136\n",
      "   macro avg       0.93      0.93      0.93       136\n",
      "weighted avg       0.93      0.93      0.93       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "confusion_matrix(y_test,y_pred_svc)\n",
    "\n",
    "cfm = confusion_matrix(y_test,y_pred_svc)\n",
    "\n",
    "print(cfm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c02aebb",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7e9a0",
   "metadata": {},
   "source": [
    "In random forest, I tried differnet n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac4f0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf accuracy is 0.9044\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_rf = {'n_estimators':[20,25,30,35,40,45,50]}\n",
    "clf_rf = GridSearchCV(rf,param_rf,cv=5,n_jobs=-1)\n",
    "clf_rf.fit(x_train,y_train)\n",
    "best_rf = clf_rf.best_estimator_\n",
    "best_rf.fit(x_train,y_train)\n",
    "y_pred_rf = best_rf.predict(x_test)\n",
    "acc_rf = accuracy_score(y_test,y_pred_rf)\n",
    "print(f'rf accuracy is {np.round(acc_rf,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3c5ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf accuracy is 0.9338\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_rf = {'n_estimators':[100,120,130,140,150,160,170]}\n",
    "clf_rf = GridSearchCV(rf,param_rf,cv=5,n_jobs=-1)\n",
    "clf_rf.fit(x_train,y_train)\n",
    "best_rf = clf_rf.best_estimator_\n",
    "best_rf.fit(x_train,y_train)\n",
    "y_pred_rf = best_rf.predict(x_test)\n",
    "acc_rf = accuracy_score(y_test,y_pred_rf)\n",
    "print(f'rf accuracy is {np.round(acc_rf,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e87403",
   "metadata": {},
   "source": [
    "Evalution of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "570908cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58  5]\n",
      " [ 4 69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93        63\n",
      "           1       0.93      0.95      0.94        73\n",
      "\n",
      "    accuracy                           0.93       136\n",
      "   macro avg       0.93      0.93      0.93       136\n",
      "weighted avg       0.93      0.93      0.93       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_rf)\n",
    "\n",
    "cfm = confusion_matrix(y_test,y_pred_rf)\n",
    "\n",
    "print(cfm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55ccf0",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aef2a3",
   "metadata": {},
   "source": [
    "In XGBoost, I tried different learning_rate and max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c008254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 800}\n",
      "[22:54:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgb accuracy is 0.9338\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=1)\n",
    "xgb_param = {'n_estimators':[400,800,1000],'learning_rate':[0.01,0.1],'max_depth':[5,6]}\n",
    "clf_xgb = GridSearchCV(xgb,xgb_param,cv=5,n_jobs=-1)\n",
    "clf_xgb.fit(x_train,y_train)\n",
    "best_xgb = clf_xgb.best_estimator_\n",
    "print(clf_xgb.best_params_)\n",
    "best_xgb.fit(x_train,y_train)\n",
    "y_pred_xgb = best_xgb.predict(x_test)\n",
    "acc_xgb = accuracy_score(y_test,y_pred_xgb)\n",
    "\n",
    "print(f'xgb accuracy is {np.round(acc_xgb,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d416455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56  7]\n",
      " [ 2 71]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93        63\n",
      "           1       0.91      0.97      0.94        73\n",
      "\n",
      "    accuracy                           0.93       136\n",
      "   macro avg       0.94      0.93      0.93       136\n",
      "weighted avg       0.94      0.93      0.93       136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_xgb)\n",
    "\n",
    "cfm = confusion_matrix(y_test,y_pred_xgb)\n",
    "\n",
    "print(cfm)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161e2907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 1000}\n",
      "[22:55:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgb accuracy is 0.9265\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=1)\n",
    "xgb_param = {'n_estimators':[400,800,1000],'learning_rate':[0.01,0.1],'max_depth':[3,4]}\n",
    "clf_xgb = GridSearchCV(xgb,xgb_param,cv=5,n_jobs=-1)\n",
    "clf_xgb.fit(x_train,y_train)\n",
    "best_xgb = clf_xgb.best_estimator_\n",
    "print(clf_xgb.best_params_)\n",
    "best_xgb.fit(x_train,y_train)\n",
    "y_pred_xgb = best_xgb.predict(x_test)\n",
    "acc_xgb = accuracy_score(y_test,y_pred_xgb)\n",
    "\n",
    "print(f'xgb accuracy is {np.round(acc_xgb,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "305b6b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
      "[22:55:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgb accuracy is 0.8162\n"
     ]
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(random_state=1)\n",
    "xgb_param = {'n_estimators':[400,800,1000],'learning_rate':[0.1,0.3],'max_depth':[5,6]}\n",
    "clf_xgb = GridSearchCV(xgb,xgb_param,cv=5,n_jobs=-1)\n",
    "clf_xgb.fit(x_train,y_train)\n",
    "best_xgb = clf_xgb.best_estimator_\n",
    "print(clf_xgb.best_params_)\n",
    "best_xgb.fit(x_train,y_train)\n",
    "y_pred_xgb = best_xgb.predict(x_test)\n",
    "acc_xgb = accuracy_score(y_test,y_pred_xgb)\n",
    "\n",
    "print(f'xgb accuracy is {np.round(acc_xgb,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730b4ee",
   "metadata": {},
   "source": [
    "Lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e141ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 4s 188ms/step - loss: 0.6914 - accuracy: 0.5257 - val_loss: 0.6875 - val_accuracy: 0.5368\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 3s 173ms/step - loss: 0.6834 - accuracy: 0.5423 - val_loss: 0.6785 - val_accuracy: 0.5368\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 3s 172ms/step - loss: 0.6636 - accuracy: 0.6544 - val_loss: 0.6682 - val_accuracy: 0.6618\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 3s 167ms/step - loss: 0.6011 - accuracy: 0.8419 - val_loss: 0.5440 - val_accuracy: 0.6912\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 3s 165ms/step - loss: 0.3309 - accuracy: 0.8897 - val_loss: 0.3032 - val_accuracy: 0.8897\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 3s 164ms/step - loss: 0.1504 - accuracy: 0.9540 - val_loss: 0.2206 - val_accuracy: 0.9044\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 0.0755 - accuracy: 0.9706 - val_loss: 0.1952 - val_accuracy: 0.9338\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 3s 160ms/step - loss: 0.0448 - accuracy: 0.9963 - val_loss: 0.2230 - val_accuracy: 0.9338\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 3s 161ms/step - loss: 0.0457 - accuracy: 0.9871 - val_loss: 0.2281 - val_accuracy: 0.8971\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 3s 158ms/step - loss: 0.0347 - accuracy: 0.9926 - val_loss: 0.2410 - val_accuracy: 0.9265\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 3s 168ms/step - loss: 0.0382 - accuracy: 0.9945 - val_loss: 0.2278 - val_accuracy: 0.9265\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 3s 172ms/step - loss: 0.0230 - accuracy: 0.9982 - val_loss: 0.3284 - val_accuracy: 0.8971\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 3s 164ms/step - loss: 0.0229 - accuracy: 0.9963 - val_loss: 0.2168 - val_accuracy: 0.9412\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 3s 165ms/step - loss: 0.0140 - accuracy: 0.9982 - val_loss: 0.2682 - val_accuracy: 0.9412\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 3s 163ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9412\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 3s 164ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.2864 - val_accuracy: 0.9485\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 3s 162ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 0.9485\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 3s 164ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9338\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 3s 172ms/step - loss: 0.0207 - accuracy: 0.9982 - val_loss: 0.4567 - val_accuracy: 0.8676\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 3s 178ms/step - loss: 0.1216 - accuracy: 0.9871 - val_loss: 0.2730 - val_accuracy: 0.8971\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2730 - accuracy: 0.8971\n",
      "0.8970588445663452\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(2000)\n",
    "voc_size = 4000\n",
    "onehoe_repr = [one_hot(words,voc_size) for words in corpus]\n",
    "sent_length = 400\n",
    "embedded_docs = pad_sequences(onehoe_repr,padding='pre',maxlen=sent_length)\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,embedding_dim,input_length=sent_length))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(np.array(embedded_docs),np.array(label),\\\n",
    "                                                 test_size=0.2,random_state=1)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=20,batch_size=32)\n",
    "acc_lstm = model.evaluate(x_test,y_test)[1]\n",
    "print(acc_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e92850",
   "metadata": {},
   "source": [
    "BiLstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4add3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "17/17 [==============================] - 8s 366ms/step - loss: 0.6909 - accuracy: 0.5294 - val_loss: 0.6877 - val_accuracy: 0.5368\n",
      "Epoch 2/20\n",
      "17/17 [==============================] - 6s 327ms/step - loss: 0.6776 - accuracy: 0.5496 - val_loss: 0.6656 - val_accuracy: 0.5368\n",
      "Epoch 3/20\n",
      "17/17 [==============================] - 6s 362ms/step - loss: 0.6322 - accuracy: 0.7610 - val_loss: 0.6245 - val_accuracy: 0.8015\n",
      "Epoch 4/20\n",
      "17/17 [==============================] - 6s 360ms/step - loss: 0.5282 - accuracy: 0.9081 - val_loss: 0.4122 - val_accuracy: 0.8676\n",
      "Epoch 5/20\n",
      "17/17 [==============================] - 6s 372ms/step - loss: 0.2584 - accuracy: 0.9320 - val_loss: 0.3340 - val_accuracy: 0.8897\n",
      "Epoch 6/20\n",
      "17/17 [==============================] - 7s 388ms/step - loss: 0.1243 - accuracy: 0.9835 - val_loss: 0.3174 - val_accuracy: 0.8382\n",
      "Epoch 7/20\n",
      "17/17 [==============================] - 7s 385ms/step - loss: 0.1376 - accuracy: 0.9559 - val_loss: 0.2819 - val_accuracy: 0.8824\n",
      "Epoch 8/20\n",
      "17/17 [==============================] - 7s 385ms/step - loss: 0.4075 - accuracy: 0.8033 - val_loss: 0.5852 - val_accuracy: 0.7426\n",
      "Epoch 9/20\n",
      "17/17 [==============================] - 7s 386ms/step - loss: 0.4015 - accuracy: 0.8915 - val_loss: 0.5566 - val_accuracy: 0.7279\n",
      "Epoch 10/20\n",
      "17/17 [==============================] - 7s 400ms/step - loss: 0.3041 - accuracy: 0.9504 - val_loss: 0.5085 - val_accuracy: 0.7353\n",
      "Epoch 11/20\n",
      "17/17 [==============================] - 7s 387ms/step - loss: 0.1978 - accuracy: 0.9816 - val_loss: 0.4172 - val_accuracy: 0.7721\n",
      "Epoch 12/20\n",
      "17/17 [==============================] - 6s 375ms/step - loss: 0.1048 - accuracy: 0.9945 - val_loss: 0.3110 - val_accuracy: 0.8382\n",
      "Epoch 13/20\n",
      "17/17 [==============================] - 7s 390ms/step - loss: 0.0607 - accuracy: 0.9945 - val_loss: 0.2823 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "17/17 [==============================] - 7s 395ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8824\n",
      "Epoch 15/20\n",
      "17/17 [==============================] - 7s 393ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.8897\n",
      "Epoch 16/20\n",
      "17/17 [==============================] - 7s 398ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9044\n",
      "Epoch 17/20\n",
      "17/17 [==============================] - 7s 387ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.7500\n",
      "Epoch 18/20\n",
      "17/17 [==============================] - 7s 387ms/step - loss: 0.0959 - accuracy: 0.9706 - val_loss: 0.5571 - val_accuracy: 0.7353\n",
      "Epoch 19/20\n",
      "17/17 [==============================] - 7s 385ms/step - loss: 0.0983 - accuracy: 0.9779 - val_loss: 0.5139 - val_accuracy: 0.7721\n",
      "Epoch 20/20\n",
      "17/17 [==============================] - 7s 392ms/step - loss: 0.0500 - accuracy: 0.9963 - val_loss: 0.4627 - val_accuracy: 0.7941\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4627 - accuracy: 0.7941\n",
      "0.7941176295280457\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(2000)\n",
    "model_bilstm=Sequential()\n",
    "model_bilstm.add(Embedding(voc_size,embedding_dim,input_length=sent_length))\n",
    "model.add(Dropout(0.5))\n",
    "model_bilstm.add(Bidirectional(LSTM(100))) # Bidirectional LSTM layer\n",
    "model_bilstm.add(Dropout(0.5))\n",
    "model_bilstm.add(Dense(1,activation='sigmoid'))\n",
    "model_bilstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_bilstm.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=20,batch_size=32)\n",
    "acc_bilstm = model_bilstm.evaluate(x_test,y_test)[1]\n",
    "print(acc_bilstm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
